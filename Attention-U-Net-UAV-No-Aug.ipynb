{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76323663-c0d3-472d-8c35-98c22f244b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Reshape, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define image dimensions and channels\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "IMG_CHANNELS = 3\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "num_classes = 1  # Single class segmentation\n",
    "\n",
    "train_image_dir = '/home/syam.varnatt/THESIS/images/train/images'\n",
    "train_mask_dir = '/home/syam.varnatt/THESIS/images/train/masks'\n",
    "val_image_dir = '/home/syam.varnatt/THESIS/images/val/images'\n",
    "val_mask_dir = '/home/syam.varnatt/THESIS/images/val/masks'\n",
    "SAVE_DIRECTORY = '/home/syam.varnatt/THESIS/attention-unet/no-aug/results'\n",
    "\n",
    "def load_dataset(image_dir, mask_dir, img_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for image_name in tqdm(os.listdir(image_dir)):\n",
    "        if image_name.lower().endswith(('.jpeg', '.jpg')):\n",
    "            base_name = os.path.splitext(image_name)[0]\n",
    "            mask_name = f\"{base_name}_mask.jpg\"\n",
    "            \n",
    "            img_path = os.path.join(image_dir, image_name)\n",
    "            mask_path = os.path.join(mask_dir, mask_name)\n",
    "            \n",
    "            if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "                try:\n",
    "                    image = load_img(img_path, target_size=img_size)\n",
    "                    mask = load_img(mask_path, target_size=img_size, color_mode=\"grayscale\")\n",
    "                    \n",
    "                    image = img_to_array(image)\n",
    "                    mask = img_to_array(mask)\n",
    "                    \n",
    "                    images.append(image)\n",
    "                    masks.append(mask)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"Mask not found for image: {image_name}\")\n",
    "    \n",
    "    images = np.array(images) / 255.0\n",
    "    masks = np.array(masks) / 255.0\n",
    "    masks = (masks > 0.5).astype(np.uint8)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "# Load datasets\n",
    "train_images, train_masks = load_dataset(train_image_dir, train_mask_dir, (IMG_HEIGHT, IMG_WIDTH))\n",
    "print(\"Training dataset loaded completely\")\n",
    "val_images, val_masks = load_dataset(val_image_dir, val_mask_dir, (IMG_HEIGHT, IMG_WIDTH))\n",
    "print(\"Validation dataset loaded completely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927f206-e017-4011-b016-530294c99498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(x, g, inter_channel):\n",
    "    theta_x = layers.Conv2D(inter_channel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    phi_g = layers.Conv2D(inter_channel, (1, 1), strides=(1, 1), padding='same')(g)\n",
    "    f = layers.Activation('relu')(layers.add([theta_x, phi_g]))\n",
    "    psi_f = layers.Conv2D(1, (1, 1), strides=(1, 1), padding='same')(f)\n",
    "    rate = layers.Activation('sigmoid')(psi_f)\n",
    "    att_x = layers.multiply([x, rate])\n",
    "    return att_x\n",
    "\n",
    "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = layers.Conv2D(filters, kernel_size=kernel_size, padding=padding, strides=strides)(x)\n",
    "    conv = layers.BatchNormalization()(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "    return conv\n",
    "\n",
    "def attention_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = conv_block(inputs, 64)\n",
    "    conv1 = conv_block(conv1, 64)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = conv_block(pool1, 128)\n",
    "    conv2 = conv_block(conv2, 128)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = conv_block(pool2, 256)\n",
    "    conv3 = conv_block(conv3, 256)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = conv_block(pool3, 512)\n",
    "    conv4 = conv_block(conv4, 512)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = conv_block(pool4, 1024)\n",
    "    conv5 = conv_block(conv5, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    att6 = attention_block(conv4, up6, 512)\n",
    "    merge6 = layers.concatenate([up6, att6], axis=3)\n",
    "    conv6 = conv_block(merge6, 512)\n",
    "    conv6 = conv_block(conv6, 512)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    att7 = attention_block(conv3, up7, 256)\n",
    "    merge7 = layers.concatenate([up7, att7], axis=3)\n",
    "    conv7 = conv_block(merge7, 256)\n",
    "    conv7 = conv_block(conv7, 256)\n",
    "\n",
    "    up8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    att8 = attention_block(conv2, up8, 128)\n",
    "    merge8 = layers.concatenate([up8, att8], axis=3)\n",
    "    conv8 = conv_block(merge8, 128)\n",
    "    conv8 = conv_block(conv8, 128)\n",
    "\n",
    "    up9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    att9 = attention_block(conv1, up9, 64)\n",
    "    \n",
    "    merge9 = layers.concatenate([up9, att9], axis=3)\n",
    "    conv9 = conv_block(merge9, 64)\n",
    "    conv9 = conv_block(conv9, 64)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model\n",
    "    \n",
    "model = attention_unet(input_shape, num_classes)\n",
    "# Compile the model with appropriate loss and metrics\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d2cc2-2103-48ad-b584-13015bccca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_images, val_masks, save_dir, num_samples=3):\n",
    "        super(VisualizationCallback, self).__init__()\n",
    "        self.val_images = val_images\n",
    "        self.val_masks = val_masks\n",
    "        self.save_dir = save_dir\n",
    "        self.num_samples = num_samples  # Number of samples to visualize per epoch\n",
    "        os.makedirs(save_dir, exist_ok=True)  # Ensure the save directory exists\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Randomly select a few samples to visualize predictions\n",
    "        idxs = np.random.choice(len(self.val_images), self.num_samples, replace=False)\n",
    "        images_to_show = self.val_images[idxs]\n",
    "        masks_to_show = self.val_masks[idxs]\n",
    "        \n",
    "        # Use the model attribute directly, which is set automatically by Keras\n",
    "        predictions = self.model.predict(images_to_show)\n",
    "\n",
    "        # Plot and save the images, masks, and predictions\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i in range(self.num_samples):\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 1)\n",
    "            plt.imshow(images_to_show[i])\n",
    "            plt.title(f'Input Image {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 2)\n",
    "            plt.imshow(masks_to_show[i].squeeze(), cmap='gray')\n",
    "            plt.title(f'True Mask {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 3)\n",
    "            plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "            plt.title(f'Predicted Mask {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # Save the plot to file\n",
    "        plt.savefig(os.path.join(self.save_dir, f'epoch_{epoch+1:02d}_predictions.png'))\n",
    "        plt.close()\n",
    "        print(f\"Saved visualization for epoch {epoch+1}.\")\n",
    "\n",
    "# Instantiate the visualization callback\n",
    "visualization_callback = VisualizationCallback(val_images, val_masks, SAVE_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f1764-5a39-439a-88ad-c17a116c6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - self.start_time\n",
    "        print(f\"Training Time: {training_time / 60:.2f} minutes\")\n",
    "\n",
    "# Create an instance of the callback\n",
    "training_time_callback = TrainingTimeCallback()\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('attention-unet.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_masks,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    batch_size=8,\n",
    "    epochs=150,\n",
    "    callbacks=[checkpoint, early_stopping, training_time_callback, visualization_callback]\n",
    ")\n",
    "\n",
    "# Save the training history to an Excel file\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_excel(os.path.join('training_history.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a72202-ed2c-41b7-b34a-fa510b499c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on validation set\n",
    "val_preds = model.predict(val_images)\n",
    "\n",
    "# Convert predictions to binary\n",
    "val_preds_bin = (val_preds > 0.3).astype(int)\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision = precision_score(val_masks.flatten(), val_preds_bin.flatten())\n",
    "f1 = f1_score(val_masks.flatten(), val_preds_bin.flatten())\n",
    "\n",
    "# Calculate Mean IoU\n",
    "mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=2) \n",
    "mean_iou_metric.update_state(val_masks, val_preds_bin)\n",
    "mean_iou = mean_iou_metric.result().numpy()\n",
    "\n",
    "# Save metrics to Excel\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'Mean IoU': [mean_iou]\n",
    "})\n",
    "print(f\"Precision: \", precision, \"F1 score: \", f1, \"Mean Iou : \", mean_iou)\n",
    "\n",
    "# Plot training history\n",
    "history_df = pd.read_excel('training_history.xlsx')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_plot.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# Save confusion matrix as heatmap\n",
    "cm = confusion_matrix(val_masks.flatten(), val_preds_bin.flatten())\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualize some predictions on validation set\n",
    "for i in range(3):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(val_images[i])\n",
    "    axs[0].set_title('Input Image')\n",
    "    axs[1].imshow(val_masks[i].squeeze(), cmap='gray')\n",
    "    axs[1].set_title('Ground Truth')\n",
    "    axs[2].imshow(val_preds_bin[i].squeeze(), cmap='gray')\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    plt.savefig(f'prediction_{i}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd950f-b291-422c-be72-af9666b703cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate inference time\n",
    "\n",
    "# Use a small batch from validation data\n",
    "sample_images = val_images[:5]\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(sample_images)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = (end_time - start_time) / len(sample_images)\n",
    "print(f\"Average Inference Time per Image: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc9031-635c-47a9-a163-1ccf495b10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define input size\n",
    "input_size = (512, 512, 3)\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path, target_size):\n",
    "    # Load image\n",
    "    image = load_img(image_path, target_size=target_size[:2])\n",
    "    # Convert to numpy array\n",
    "    image_array = img_to_array(image)\n",
    "    # Normalize the image\n",
    "    image_array = image_array / 255.0\n",
    "    return image_array\n",
    "\n",
    "# Function to save images\n",
    "def save_image(image_array, save_path):\n",
    "    # Convert array to image\n",
    "    image = array_to_img(image_array)\n",
    "    # Save the image\n",
    "    image.save(save_path)\n",
    "\n",
    "# Function to display images\n",
    "def display_images(images, titles=None, cmap='gray'):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(3, 4, i + 1)  # Adjust depending on the number of images\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder = '/home/syam.varnatt/THESIS/Plot_Images(x10,x20)'\n",
    "image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith('.png')]\n",
    "\n",
    "# Sort the image paths by filenames\n",
    "image_paths = sorted(image_paths)\n",
    "\n",
    "# Select a subset of images\n",
    "image_paths = image_paths[0:]\n",
    "\n",
    "# Predict segmentation masks for each image\n",
    "# Extract image names from paths\n",
    "image_names = [os.path.basename(path) for path in image_paths]\n",
    "\n",
    "# Define the folder path to save images and masks\n",
    "save_folder = '/home/syam.varnatt/THESIS/attention-unet/no-aug/predict_height'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Predict segmentation masks and save images and masks\n",
    "predicted_masks = []\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # Preprocess image\n",
    "    image = preprocess_image(image_path, input_size)\n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "    # Predict mask\n",
    "    predicted_mask = model.predict(image_batch)[0]\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Save the original image\n",
    "    original_image = img_to_array(load_img(image_path, target_size=input_size[:2])) / 255.0\n",
    "    save_image(original_image, os.path.join(save_folder, f'original_{image_names[i]}'))\n",
    "    \n",
    "    # Save the predicted mask\n",
    "    save_image(predicted_mask, os.path.join(save_folder, f'mask_{image_names[i]}'))\n",
    "    \n",
    "    predicted_masks.append(predicted_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01793b67-1b61-4378-83e4-b8b63c7df06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate inference time for predicting heights\n",
    "\n",
    "# Use a small batch from validation data\n",
    "sample_images = image_batch[:5]\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(sample_images)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = (end_time - start_time) / len(sample_images)\n",
    "print(f\"Average Inference Time per flight height predicted Image: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b5121-ed7c-4272-805a-e0a30523cdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
